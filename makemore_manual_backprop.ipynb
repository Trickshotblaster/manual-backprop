{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of names: 32033\n",
      "Max name length: 15\n",
      "First 8 names: ['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']\n"
     ]
    }
   ],
   "source": [
    "with open(\"names.txt\", \"r\") as f:\n",
    "    words = f.read().splitlines()\n",
    "print(f\"Number of names: {len(words)}\")\n",
    "print(f\"Max name length: {max(len(word) for word in words)}\")\n",
    "print(f\"First 8 names: {words[:8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 27\n",
      "{'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26, '.': 0}\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(set(\"\".join(words)))\n",
    "stoi = {char:i+1 for i, char in enumerate(chars)}\n",
    "stoi[\".\"] = 0\n",
    "itos = {i:char for i, char in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(\"Vocab size:\", vocab_size)\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131200, 3]) torch.Size([131200, 1])\n",
      "torch.Size([16440, 3]) torch.Size([16440, 1])\n",
      "torch.Size([16440, 3]) torch.Size([16440, 1])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):\n",
    "    x, y = [], []\n",
    "    for word in words:\n",
    "        context = [0] * block_size\n",
    "        for char, next in zip(word, word[1:]):\n",
    "            x.append(context)\n",
    "            y.append([stoi[next]])\n",
    "            context = context[1:] + [stoi[char]]\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "import random\n",
    "random.shuffle(words)\n",
    "split1 = int(0.8*len(words))\n",
    "split2 = int(0.9*len(words))\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:split1])\n",
    "Xdev, Ydev = build_dataset(words[split1:split2])\n",
    "Xte, Yte = build_dataset(words[split2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(s, dt, t):\n",
    "    ex = torch.all(dt == t.grad).item()\n",
    "    app = torch.allclose(dt, t.grad)\n",
    "    maxdiff = (dt - t.grad).abs().max().item()\n",
    "    print(f\"{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 64\n",
    "\n",
    "C = torch.randn((vocab_size, n_embd))\n",
    "w1 = torch.randn((n_embd * block_size, n_hidden)) * (5/3)/((n_embd*block_size)**0.5)\n",
    "b1 = torch.randn((n_hidden)) * 0.1\n",
    "w2 = torch.randn((n_hidden, vocab_size)) *0.1#/ (n_embd * block_size)**0.5\n",
    "b2 = torch.randn((vocab_size)) * 0.1\n",
    "\n",
    "bngain = torch.randn((1, n_hidden)) * 0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden)) * 0.1\n",
    "\n",
    "parameters = [C, w1, b1, w2, b2, bngain, bnbias]\n",
    "print(sum(p.numel() for p in parameters))\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "\n",
    "idx = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "Xb, Yb = Xtr[idx], Ytr[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4099, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding\n",
    "emb = C[Xb]\n",
    "embcat = emb.view(batch_size, -1)\n",
    "# layer 1\n",
    "hprebn = embcat @ w1 + b1\n",
    "# batchnorm\n",
    "bnmeani = hprebn.sum(0, keepdim=True) * (1/n) # = sum/n = mean\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff ** 2\n",
    "bnvar = bndiff2.sum(0, keepdim=True) * (1/(n-1))\n",
    "bnvar_inv = (bnvar + 1e-5) ** -0.5\n",
    "bnraw = bndiff * bnvar_inv # (x-mean) / std\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# output\n",
    "h = torch.tanh(hpreact)\n",
    "logits = h @ w2 + b2\n",
    "\n",
    "# loss (cross-entropy)\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdim=True)\n",
    "counts_sum_inv = counts_sum ** -1\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# pytorch backward\n",
    "for p in parameters:\n",
    "    p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
    "           norm_logits, logit_maxes, logits, h, hpreact,\n",
    "             bnraw, bnvar_inv, bnvar, bndiff2, bndiff, hprebn,\n",
    "               bnmeani, embcat, emb]:\n",
    "    t.retain_grad()\n",
    "loss.backward()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for p in parameters:\n",
    "    plt.hist(p.grad.detach().view(-1).tolist())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: False | approximate: True  | maxdiff: 2.9802322387695312e-08\n",
      "counts_sum_inv  | exact: False | approximate: True  | maxdiff: 2.9802322387695312e-08\n",
      "counts_sum      | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-10\n",
      "counts          | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "norm_logits     | exact: False | approximate: True  | maxdiff: 4.656612873077393e-10\n",
      "logit_maxes     | exact: False | approximate: True  | maxdiff: 5.122274160385132e-09\n",
      "logits          | exact: False | approximate: True  | maxdiff: 4.889443516731262e-09\n",
      "h               | exact: False | approximate: True  | maxdiff: 1.2223608791828156e-09\n",
      "w2              | exact: False | approximate: True  | maxdiff: 2.0489096641540527e-08\n",
      "b2              | exact: False | approximate: True  | maxdiff: 1.4901161193847656e-08\n",
      "hpreact         | exact: False | approximate: True  | maxdiff: 1.280568540096283e-09\n",
      "bnraw           | exact: False | approximate: True  | maxdiff: 1.280568540096283e-09\n",
      "bnvar_inv       | exact: False | approximate: True  | maxdiff: 3.259629011154175e-09\n",
      "bnvar           | exact: False | approximate: True  | maxdiff: 1.0477378964424133e-09\n",
      "bngain          | exact: False | approximate: True  | maxdiff: 2.3283064365386963e-09\n",
      "bnbias          | exact: False | approximate: True  | maxdiff: 5.587935447692871e-09\n",
      "bndiff2         | exact: False | approximate: True  | maxdiff: 3.2741809263825417e-11\n",
      "bndiff          | exact: False | approximate: True  | maxdiff: 1.0186340659856796e-09\n",
      "bnmeani         | exact: False | approximate: True  | maxdiff: 3.725290298461914e-09\n",
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.89530235528946e-10\n",
      "w1              | exact: False | approximate: True  | maxdiff: 8.381903171539307e-09\n",
      "b1              | exact: False | approximate: True  | maxdiff: 3.14321368932724e-09\n",
      "embcat          | exact: False | approximate: True  | maxdiff: 1.3387762010097504e-09\n",
      "emb             | exact: False | approximate: True  | maxdiff: 1.3387762010097504e-09\n",
      "C               | exact: False | approximate: True  | maxdiff: 6.05359673500061e-09\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually,\n",
    "# backpropagating through exactly all of the variables\n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs) \n",
    "for b in range(n):\n",
    "    for y in Yb:\n",
    "        dlogprobs[b, y] += -1/logprobs[range(n), Yb].numel()\n",
    "\n",
    "dprobs = dlogprobs * (1/probs) # chain rule\n",
    "dcounts_sum_inv = (dprobs * counts).sum(1, keepdim=True) # I guess we have to apply all shape-changing operations to derivative\n",
    "dcounts_sum = dcounts_sum_inv * -counts_sum**-2\n",
    "# dloss/dcounts = dloss/dcounts_sum * dcounts_sum/dcounts\n",
    "# dcounts_sum/d_counts should be 1s in the shape of counts\n",
    "# assuming counts is [[a, b], [c, d]],\n",
    "# counts_sum = \n",
    "# [[a, b],\n",
    "# [c, d]].sum(1, keepdim=True)\n",
    "# --> \n",
    "# [[a+c],\n",
    "# [b+d]]\n",
    "# Therefore dcounts_sum/da = 1 + 0 = 1\n",
    "# dcounts_sum/db = 0 + 1 = 1\n",
    "# etc ->\n",
    "# counts_grad = \n",
    "# [[1, 1],\n",
    "# [1, 1]]\n",
    "# So, by chain rule, dloss/dcounts = dloss/dcounts_sum * dcounts_sum/dcounts\n",
    "# = dloss/dcounts_sum * counts_grad (ones in shape of counts)\n",
    "# counts are also used in calculation of probs\n",
    "# so just add dcounts/dloss using chain rule with probs\n",
    "dcounts = dcounts_sum * torch.ones_like(counts) + counts_sum_inv * dprobs\n",
    "dnorm_logits = counts * dcounts\n",
    "# ok so max is a little weird\n",
    "# imagine you have a tensor a = [[0.2, 6.9], [-1.4, 3.2]]\n",
    "# and then you take the max of it and transform that to get an output\n",
    "# if you shift a by a tiny amount to get the gradient of the max of a,\n",
    "# the max of a will not change, therefore the gradient of the max is zero\n",
    "dlogit_maxes = -1 * torch.zeros_like(logit_maxes)\n",
    "dlogits = 0 + dnorm_logits * 1 # dloss/dlogit_maxes * dlogit_maxes/dlogits + dloss/dnorm_logits * dnorm_logits/dlogits\n",
    "dh = dlogits @ w2.T # dloss/dlogits * dlogits/dh = dlogits * w2 (derivative of matmul is to matmul by transpose??)\n",
    "dw2 = h.T @ dlogits # ok so its matmul by transpose but make sure its on the same side as before\n",
    "# also it no longer says its an approximate here but the max diff is 6e-8 which seems like floating point error to me\n",
    "db2 = torch.ones_like(b2) * dlogits.sum(0, keepdim=True) # dlogits/db2 is just going to be 1s in the shape of b2\n",
    "# but we also need to apply chain rule by multiplying by dloss/dlogits\n",
    "# the problem is that dlogits is (32, 27), while db2 is (27)\n",
    "# we can force dlogits to be (1, 27) by summing along dim 0\n",
    "# tbh idk why this works \\_(\"/)_/\n",
    "dhpreact = (1/(torch.pow((torch.exp(hpreact) + torch.exp(-hpreact))/2, 2))) * dh # thanks calculus 1\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True) # sum is a lifesaver and idek why it works\n",
    "dbnbias = 1 * dhpreact.sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True) \n",
    "dbnvar = -0.5*(bnvar + 1e-5)**-1.5 * dbnvar_inv\n",
    "dbndiff2 = 1/(n-1) * dbnvar\n",
    "dbndiff = 2 * bndiff * dbndiff2 + bnvar_inv.expand(bndiff.size()) * dbnraw\n",
    "dbnmeani = -1 * dbndiff.sum(0, keepdim=True)\n",
    "dhprebn = 1/n * dbnmeani + 1 * dbndiff\n",
    "dw1 = embcat.T @ dhprebn # again it says not approximate but 3e-8 diff is too small\n",
    "db1 = 1.0 * dhprebn.sum(0, keepdim=True)\n",
    "dembcat = dhprebn @ w1.T\n",
    "demb = dembcat.view(emb.size())\n",
    "dC = torch.zeros_like(C)\n",
    "for num, b in enumerate(Xb):\n",
    "     for num2, i in enumerate(b):\n",
    "         dC[i] += demb[num][num2]\n",
    "# -------------------------------------------------------------------------------------------\n",
    "cmp(\"logprobs\", dlogprobs, logprobs)\n",
    "cmp(\"probs\", dprobs, probs)\n",
    "cmp(\"counts_sum_inv\", dcounts_sum_inv, counts_sum_inv)\n",
    "cmp(\"counts_sum\", dcounts_sum, counts_sum)\n",
    "cmp(\"counts\", dcounts, counts)\n",
    "cmp(\"norm_logits\", dnorm_logits, norm_logits)\n",
    "cmp(\"logit_maxes\", dlogit_maxes, logit_maxes)\n",
    "cmp(\"logits\", dlogits, logits)\n",
    "cmp(\"h\", dh, h)\n",
    "cmp(\"w2\", dw2, w2)\n",
    "cmp(\"b2\", db2, b2)\n",
    "cmp(\"hpreact\", dhpreact, hpreact)\n",
    "cmp(\"bnraw\", dbnraw, bnraw)\n",
    "cmp(\"bnvar_inv\", dbnvar_inv, bnvar_inv)\n",
    "cmp(\"bnvar\", dbnvar, bnvar)\n",
    "cmp(\"bngain\", dbngain, bngain)\n",
    "cmp(\"bnbias\", dbnbias, bnbias)\n",
    "cmp(\"bndiff2\", dbndiff2, bndiff2)\n",
    "cmp(\"bndiff\", dbndiff, bndiff)\n",
    "cmp(\"bnmeani\", dbnmeani, bnmeani)\n",
    "cmp(\"hprebn\", dhprebn, hprebn)\n",
    "cmp(\"w1\", dw1, w1)\n",
    "cmp(\"b1\", db1, b1)\n",
    "cmp(\"embcat\", dembcat, embcat)\n",
    "cmp(\"emb\", demb, emb)\n",
    "cmp(\"C\", dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-2., grad_fn=<SumBackward0>)\n",
      "1\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\brodi\\AppData\\Local\\Temp\\ipykernel_12784\\1971916642.py:8: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  print(A.grad)\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True).max(1, keepdim=True).values\n",
    "B = torch.tensor([[1., 2.], [3., 4.]], requires_grad=True)\n",
    "f = (B-A).sum()\n",
    "print(f)\n",
    "expected = 1\n",
    "print(expected)\n",
    "f.backward()\n",
    "print(A.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0412,  0.7524,  0.0895,  0.1979],\n",
      "        [-0.4305,  0.4313,  0.4427,  0.0980],\n",
      "        [-0.1568,  0.1848,  0.2551,  0.0394]])\n",
      "tensor([[-1.0412,  0.7524,  0.0895,  0.1979],\n",
      "        [-0.4305,  0.4313,  0.4427,  0.0980],\n",
      "        [-0.1568,  0.1848,  0.2551,  0.0394]])\n"
     ]
    }
   ],
   "source": [
    "Y = torch.zeros((3, 4))\n",
    "X = torch.randn((3, 2))\n",
    "A = torch.randn((2, 4))\n",
    "for i in range(X.size(0)):\n",
    "    for j in range(A.size(1)):\n",
    "        Y[i, j] = sum(X[i, k] * A[k, j] for k in range(A.size(0)))\n",
    "print(Y)\n",
    "print(X @ A)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
